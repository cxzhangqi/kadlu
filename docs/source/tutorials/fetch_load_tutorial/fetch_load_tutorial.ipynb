{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching and Loading Environmental Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use Kadlu to retrieve environmental data from online sources and load the data into numpy arrays for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, we import all necessary python modules, functions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from kadlu import chs, era5, hycom, wwiii, source_map, data_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick start guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Kadlu, environmental data can be retrieved and loaded with a single line of code. Here, we demonstrate how to obtain modelled, surface salinity data from HYCOM for the geographic region $47^{\\circ}$N to $49^{\\circ}$N and $-63^{\\circ}$W to $-61^{\\circ}$W for the first week of January 2013.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fetch and load salinity (g/kg salt in water)\n",
    "salinity, lat, lon, epoch, depth = hycom().load_salinity(\n",
    "        south=47, west=-63, \n",
    "        north=49, east=-61, \n",
    "        bottom=0, top=0,\n",
    "        start=datetime(2013, 1, 1), end=datetime(2013, 1, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the arguments `bottom` and `top` are both set to `0`, thereby selecting only data at a depth of 0 m, i.e., at the surface. Note also that we use the [datetime](https://docs.python.org/2/library/datetime.html) package to specify dates and times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_salinity` method produced flattened numpy arrays, the length of which corresponds to the number of data points in the selected geographic region, depth range, and temporal window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47. 47. 47. 47. 47. 47. 47. 47. 47. 47.]\n",
      "[-62.96002197 -62.88000488 -62.79998779 -62.7199707  -62.64001465\n",
      " -62.55999756 -62.47998047 -62.40002441 -62.32000732 -62.23999023]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[113991. 113991. 113991. 113991. 113991. 113991. 113991. 113991. 113991.\n",
      " 113991.]\n",
      "[30.791 30.886 30.92  30.903 30.874 30.853 30.817 30.747 30.714 30.636]\n"
     ]
    }
   ],
   "source": [
    "# print the first 10 values of each array\n",
    "\n",
    "print(lat[0:10])      # latitude (degrees north)\n",
    "print(lon[0:10])      # longitude (degrees west)\n",
    "print(depth[0:10])    # depth (meters)\n",
    "print(epoch[0:10])     # time (hours since 00:00:00 on 1 January 2000)\n",
    "print(salinity[0:10]) # ocean salt content (g/kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `epoch_2_dt` function from Kadlu's `data_util` module to convert the time values into a more human-friendly date-time format, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-01 15:00:00\n"
     ]
    }
   ],
   "source": [
    "print(data_util.epoch_2_dt(epoch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sources\n",
    "Kadlu includes functionality to load data from a variety of different data sources. For a high level overview, print the source_map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    CHS   (Canadian Hydrography Service)\n",
      "          load_bathymetry:          bathymetric data in Canada's waterways. variable resolution \n",
      "\n",
      "    ERA5  (Global environmental dataset from Copernicus Climate Data Store)\n",
      "          load_windwaveswellheight: combined height of wind, waves, and swell. metres\n",
      "          load_wavedirection:       mean wave direction, degrees\n",
      "          load_waveperiod:          mean wave period, seconds\n",
      "          load_wind_uv:             wind speed computed as sqrt(u^2 + v^2) / 2, where u, v are direction vectors\n",
      "          load_wind_u:              wind speed coordinate U-vector, m/s\n",
      "          load_wind_v:              wind speed coordinate V-vector, m/s \n",
      "\n",
      "    HYCOM (Hybrid Coordinate Ocean Model)\n",
      "          load_salinity:            g/kg salt in water\n",
      "          load_temp:                degrees celsius\n",
      "          load_water_uv:            ocean current computed as sqrt(u^2 + v^2) / 2, where u, v are direction vectors\n",
      "          load_water_u:             ocean current coordinate U-vector, m/s\n",
      "          load_water_v:             ocean current coordinate V-vector, m/s \n",
      "\n",
      "    WWIII (WaveWatch Ocean Model Gen 3)\n",
      "          load_wavedirection:       primary wave direction, degrees\n",
      "          load_waveperiod:          primary mean wave period, seconds\n",
      "          load_windwaveheight:      combined height of wind and waves, metres\n",
      "          load_wind_uv:             wind speed computed as sqrt(u^2 + v^2) / 2, where u, v are direction vectors\n",
      "          load_wind_u:              wind speed coordinate U-vector, m/s\n",
      "          load_wind_v:              wind speed coordinate V-vector, m/s\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(source_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for more information on a specific source, print the class object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Native hycom .[ab] data converted to NetCDF at the Naval\n",
      "Research Laboratory, interpolated to 0.08째 grid between\n",
      "40째S-40째N (0.04째 poleward) containing 40 z-levels.\n",
      "Availability: 1994 to 2015\n",
      "\thttps://www.hycom.org/data/glbv0pt08\n",
      "\n",
      "function input arguments:\n",
      "\t(south, north, west, east, start, end, top, bottom)\n",
      "\n",
      "class functions:\n",
      "\tload_salinity\n",
      "\tload_temp\n",
      "\tload_water_u\n",
      "\tload_water_uv\n",
      "\tload_water_v\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hycom())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keyword arguments can be passed as a dictionary when using the same load arguments for multiple datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHS bathymetry: processing 16 files\n",
      "CHS CA2_4600N06100W.tif bathymetry: processed and inserted 73596 rows. 928405 null values removed, 0 duplicate rows ignored\n",
      "CHS CA2_4600N06200W.tif bathymetry: processed and inserted 0 rows. 938631 null values removed, 63370 duplicate rows ignored\n",
      "CHS CA2_4600N06300W.tif bathymetry: processed and inserted 0 rows. 901841 null values removed, 100160 duplicate rows ignored\n",
      "CHS CA2_4600N06400W.tif bathymetry: processed and inserted 0 rows. 844720 null values removed, 157281 duplicate rows ignored\n",
      "CHS CA2_4700N06100W.tif bathymetry: processed and inserted 23357 rows. 978644 null values removed, 0 duplicate rows ignored\n",
      "CHS CA2_4700N06200W.tif bathymetry: processed and inserted 0 rows. 528221 null values removed, 473780 duplicate rows ignored\n",
      "CHS CA2_4700N06300W.tif bathymetry: processed and inserted 0 rows. 910618 null values removed, 91383 duplicate rows ignored\n",
      "CHS CA2_4700N06400W.tif bathymetry: processed and inserted 0 rows. 994983 null values removed, 7018 duplicate rows ignored\n",
      "CHS CA2_4800N06100W.tif bathymetry: processed and inserted 8554 rows. 993447 null values removed, 0 duplicate rows ignored\n",
      "CHS CA2_4800N06200W.tif bathymetry: processed and inserted 18814 rows. 983187 null values removed, 0 duplicate rows ignored\n",
      "CHS CA2_4800N06300W.tif bathymetry: processed and inserted 20293 rows. 981708 null values removed, 0 duplicate rows ignored\n",
      "CHS CA2_4800N06400W.tif bathymetry: processed and inserted 338216 rows. 663785 null values removed, 0 duplicate rows ignored\n",
      "CHS CA2_4900N06100W.tif bathymetry: processed and inserted 50555 rows. 951446 null values removed, 0 duplicate rows ignored\n",
      "CHS CA2_4900N06200W.tif bathymetry: processed and inserted 68593 rows. 933408 null values removed, 0 duplicate rows ignored\n",
      "CHS CA2_4900N06300W.tif bathymetry: processed and inserted 85018 rows. 916983 null values removed, 0 duplicate rows ignored\n",
      "CHS CA2_4900N06400W.tif bathymetry: processed and inserted 265057 rows. 736944 null values removed, 0 duplicate rows ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-03 13:20:51,037 INFO Welcome to the CDS\n",
      "2020-03-03 13:20:51,040 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2020-03-03 13:20:54,053 INFO Request is queued\n",
      "2020-03-03 13:20:56,857 INFO Request is running\n",
      "2020-03-03 13:21:02,794 INFO Request is completed\n",
      "2020-03-03 13:21:02,796 INFO Downloading http://136.156.132.210/cache-compute-0005/cache/data2/adaptor.mars.internal-1583256056.1745522-19056-8-6f74b241-1567-4cf4-8bea-37fbb68846ca.grib to /storage/ERA5_reanalysis_significant_height_of_combined_wind_waves_and_swell_2013-01-01.grb2 (7.3M)\n",
      "2020-03-03 13:21:05,994 INFO Download rate 2.3M/s\n",
      "2020-03-03 13:21:11,965 INFO Welcome to the CDS\n",
      "2020-03-03 13:21:11,966 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2020-03-03 13:21:13,313 INFO Request is queued\n",
      "2020-03-03 13:21:24,485 INFO Request is running\n",
      "2020-03-03 13:21:29,701 INFO Request is completed\n",
      "2020-03-03 13:21:29,703 INFO Downloading http://136.156.132.236/cache-compute-0007/cache/data9/adaptor.mars.internal-1583256083.5988646-28970-32-49274a18-df7d-4aa1-a0e2-56498018428a.grib to /storage/ERA5_reanalysis_significant_height_of_combined_wind_waves_and_swell_2013-01-02.grb2 (7.3M)\n",
      "2020-03-03 13:21:31,605 INFO Download rate 3.8M/s\n",
      "2020-03-03 13:21:35,183 INFO Welcome to the CDS\n",
      "2020-03-03 13:21:35,185 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2020-03-03 13:21:35,646 INFO Request is queued\n",
      "2020-03-03 13:21:36,799 INFO Request is running\n",
      "2020-03-03 13:21:40,857 INFO Request is completed\n",
      "2020-03-03 13:21:40,858 INFO Downloading http://136.156.132.105/cache-compute-0000/cache/data2/adaptor.mars.internal-1583256096.2115095-18232-34-6874ae51-3d30-4458-bf7c-a817b47cdcdd.grib to /storage/ERA5_reanalysis_significant_height_of_combined_wind_waves_and_swell_2013-01-03.grb2 (7.3M)\n",
      "2020-03-03 13:21:42,498 INFO Download rate 4.4M/s\n",
      "2020-03-03 13:21:46,049 INFO Welcome to the CDS\n",
      "2020-03-03 13:21:46,052 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2020-03-03 13:21:46,601 INFO Request is queued\n",
      "2020-03-03 13:21:49,405 INFO Request is running\n",
      "2020-03-03 13:21:55,340 INFO Request is completed\n",
      "2020-03-03 13:21:55,341 INFO Downloading http://136.156.132.235/cache-compute-0006/cache/data5/adaptor.mars.internal-1583256108.2023842-1887-30-759f9ddd-b179-48e7-8081-0c8c1142811f.grib to /storage/ERA5_reanalysis_significant_height_of_combined_wind_waves_and_swell_2013-01-04.grb2 (7.3M)\n",
      "2020-03-03 13:21:57,244 INFO Download rate 3.8M/s\n",
      "2020-03-03 13:22:01,149 INFO Welcome to the CDS\n",
      "2020-03-03 13:22:01,150 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2020-03-03 13:22:01,703 INFO Request is queued\n",
      "2020-03-03 13:22:02,856 INFO Request is running\n",
      "2020-03-03 13:22:06,912 INFO Request is completed\n",
      "2020-03-03 13:22:06,914 INFO Downloading http://136.156.133.42/cache-compute-0014/cache/data8/adaptor.mars.internal-1583256122.7105417-4573-11-90a3f0c5-a30f-4389-afea-8f9b4a917a3f.grib to /storage/ERA5_reanalysis_significant_height_of_combined_wind_waves_and_swell_2013-01-05.grb2 (7.3M)\n",
      "2020-03-03 13:22:08,817 INFO Download rate 3.8M/s\n",
      "2020-03-03 13:22:13,059 INFO Welcome to the CDS\n",
      "2020-03-03 13:22:13,060 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2020-03-03 13:22:14,189 INFO Request is queued\n",
      "2020-03-03 13:22:16,994 INFO Request is running\n",
      "2020-03-03 13:22:19,396 INFO Request is completed\n",
      "2020-03-03 13:22:19,398 INFO Downloading http://136.156.133.37/cache-compute-0011/cache/data9/adaptor.mars.internal-1583256136.2202325-30205-23-41d21171-8465-4748-9c29-ae4f060f8293.grib to /storage/ERA5_reanalysis_significant_height_of_combined_wind_waves_and_swell_2013-01-06.grb2 (7.3M)\n",
      "2020-03-03 13:22:21,167 INFO Download rate 4.1M/s\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(\n",
    "        south=47, west=-63, \n",
    "        north=49, east=-61, \n",
    "        bottom=0, top=0,\n",
    "        start=datetime(2013, 1, 1), end=datetime(2013, 1, 7))\n",
    "\n",
    "bathy, lat1, lon1 = chs().load_bathymetry(**kwargs)\n",
    "waveheight, lat2, lon2, epoch2 = era5().load_windwaveswellheight(**kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
