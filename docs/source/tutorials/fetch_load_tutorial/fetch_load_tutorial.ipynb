{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching and Loading Environmental Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use Kadlu to retrieve environmental data from online sources and load the data into numpy arrays for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, we import all necessary python modules, functions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import kadlu\n",
    "from kadlu import chs, era5, gebco, hycom, wwiii, source_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick start guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Kadlu, environmental data can be downloaded and stored in one step. Here, we demonstrate how to obtain modeled surface salinity data from HYCOM for the geographic region $47^{\\circ}$N to $49^{\\circ}$N and $-63^{\\circ}$W to $-61^{\\circ}$W for the first week of January 2013.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 02:13:08  HYCOM 2013-01-01 downloading 212160 salinity values in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:13:23  HYCOM 2013-01-01 salinity: downloaded 215 Kb in 14.681s. parsed and inserted 60772 rows in 1.120s. 151388 null values removed, 0 duplicates ignored\n",
      "2020-06-15 02:13:23  HYCOM 2013-01-01 downloading 212160 salinity values in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:13:33  HYCOM 2013-01-01 salinity: downloaded 213 Kb in 8.175s. parsed and inserted 86416 rows in 1.809s. 123996 null values removed, 1748 duplicates ignored\n",
      "2020-06-15 02:13:33  HYCOM 2013-01-01 downloading 212160 salinity values in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:13:38  HYCOM 2013-01-01 salinity: downloaded 215 Kb in 3.194s. parsed and inserted 64540 rows in 1.155s. 145200 null values removed, 2420 duplicates ignored\n",
      "2020-06-15 02:13:38  HYCOM 2013-01-01 downloading 212160 salinity values in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:13:40  HYCOM 2013-01-01 salinity: downloaded 209 Kb in 0.788s. parsed and inserted 113976 rows in 1.917s. 92292 null values removed, 5892 duplicates ignored\n",
      "2020-06-15 02:13:40  HYCOM 2013-01-02 downloading 477360 salinity values in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:14:18  HYCOM 2013-01-02 salinity: downloaded 485 Kb in 35.436s. parsed and inserted 121544 rows in 1.806s. 340623 null values removed, 15193 duplicates ignored\n",
      "2020-06-15 02:14:18  HYCOM 2013-01-02 downloading 477360 salinity values in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:14:54  HYCOM 2013-01-02 salinity: downloaded 479 Kb in 33.855s. parsed and inserted 172832 rows in 2.918s. 278991 null values removed, 25537 duplicates ignored\n",
      "2020-06-15 02:14:54  HYCOM 2013-01-02 downloading 477360 salinity values in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:15:21  HYCOM 2013-01-02 salinity: downloaded 483 Kb in 25.480s. parsed and inserted 129080 rows in 1.936s. 326700 null values removed, 21580 duplicates ignored\n",
      "2020-06-15 02:15:21  HYCOM 2013-01-02 downloading 477360 salinity values in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:15:43  HYCOM 2013-01-02 salinity: downloaded 470 Kb in 19.196s. parsed and inserted 227952 rows in 3.728s. 207657 null values removed, 41751 duplicates ignored\n",
      "2020-06-15 02:15:43  HYCOM 2013-01-03 downloading 477360 salinity values in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:16:15  HYCOM 2013-01-03 salinity: downloaded 485 Kb in 29.423s. parsed and inserted 121544 rows in 2.564s. 340623 null values removed, 15193 duplicates ignored\n",
      "2020-06-15 02:16:15  HYCOM 2013-01-03 downloading 477360 salinity values in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:16:37  HYCOM 2013-01-03 salinity: downloaded 479 Kb in 17.546s. parsed and inserted 172832 rows in 3.876s. 278991 null values removed, 25537 duplicates ignored\n",
      "2020-06-15 02:16:37  HYCOM 2013-01-03 downloading 477360 salinity values in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:16:51  HYCOM 2013-01-03 salinity: downloaded 483 Kb in 12.549s. parsed and inserted 129080 rows in 1.943s. 326700 null values removed, 21580 duplicates ignored\n",
      "2020-06-15 02:16:51  HYCOM 2013-01-03 downloading 477360 salinity values in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:16:55  HYCOM 2013-01-03 salinity: downloaded 470 Kb in 0.958s. parsed and inserted 227952 rows in 3.211s. 207657 null values removed, 41751 duplicates ignored\n",
      "2020-06-15 02:16:55  HYCOM 2013-01-04 downloading 477360 salinity values in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:17:27  HYCOM 2013-01-04 salinity: downloaded 485 Kb in 29.303s. parsed and inserted 121544 rows in 1.852s. 340623 null values removed, 15193 duplicates ignored\n",
      "2020-06-15 02:17:27  HYCOM 2013-01-04 downloading 477360 salinity values in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:17:56  HYCOM 2013-01-04 salinity: downloaded 479 Kb in 26.272s. parsed and inserted 172832 rows in 2.922s. 278991 null values removed, 25537 duplicates ignored\n",
      "2020-06-15 02:17:56  HYCOM 2013-01-04 downloading 477360 salinity values in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:18:16  HYCOM 2013-01-04 salinity: downloaded 483 Kb in 17.910s. parsed and inserted 129080 rows in 2.611s. 326700 null values removed, 21580 duplicates ignored\n",
      "2020-06-15 02:18:16  HYCOM 2013-01-04 downloading 477360 salinity values in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:19:03  HYCOM 2013-01-04 salinity: downloaded 470 Kb in 43.635s. parsed and inserted 227952 rows in 3.255s. 207657 null values removed, 41751 duplicates ignored\n",
      "2020-06-15 02:19:03  HYCOM 2013-01-05 downloading 477360 salinity values in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:19:45  HYCOM 2013-01-05 salinity: downloaded 485 Kb in 40.228s. parsed and inserted 121544 rows in 1.920s. 340623 null values removed, 15193 duplicates ignored\n",
      "2020-06-15 02:19:45  HYCOM 2013-01-05 downloading 477360 salinity values in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:20:17  HYCOM 2013-01-05 salinity: downloaded 479 Kb in 28.121s. parsed and inserted 172832 rows in 4.463s. 278991 null values removed, 25537 duplicates ignored\n",
      "2020-06-15 02:20:17  HYCOM 2013-01-05 downloading 477360 salinity values in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:20:48  HYCOM 2013-01-05 salinity: downloaded 483 Kb in 28.471s. parsed and inserted 129080 rows in 2.587s. 326700 null values removed, 21580 duplicates ignored\n",
      "2020-06-15 02:20:48  HYCOM 2013-01-05 downloading 477360 salinity values in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:21:04  HYCOM 2013-01-05 salinity: downloaded 470 Kb in 12.357s. parsed and inserted 227952 rows in 3.341s. 207657 null values removed, 41751 duplicates ignored\n",
      "2020-06-15 02:21:04  HYCOM 2013-01-06 downloading 424320 salinity values in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:21:32  HYCOM 2013-01-06 salinity: downloaded 431 Kb in 25.582s. parsed and inserted 106351 rows in 1.967s. 302776 null values removed, 15193 duplicates ignored\n",
      "2020-06-15 02:21:32  HYCOM 2013-01-06 downloading 424320 salinity values in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m...\n",
      "2020-06-15 02:21:56  HYCOM 2013-01-06 salinity: downloaded 426 Kb in 20.408s. parsed and inserted 151228 rows in 4.414s. 247992 null values removed, 25100 duplicates ignored\n",
      "2020-06-15 02:21:56  HYCOM 2013-01-06 downloading 424320 salinity values in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:22:12  HYCOM 2013-01-06 salinity: downloaded 430 Kb in 12.413s. parsed and inserted 112945 rows in 2.603s. 290400 null values removed, 20975 duplicates ignored\n",
      "2020-06-15 02:22:12  HYCOM 2013-01-06 downloading 424320 salinity values in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m...\n",
      "2020-06-15 02:22:32  HYCOM 2013-01-06 salinity: downloaded 418 Kb in 17.156s. parsed and inserted 199458 rows in 2.957s. 184584 null values removed, 40278 duplicates ignored\n"
     ]
    }
   ],
   "source": [
    "# fetch and load salinity (g/kg salt in water)\n",
    "salinity, lat, lon, epoch, depth = hycom().load_salinity(\n",
    "        south=47, west=-63, \n",
    "        north=49, east=-61, \n",
    "        bottom=0, top=0,\n",
    "        start=datetime(2013, 1, 1), end=datetime(2013, 1, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the arguments `bottom` and `top` are both set to `0`, thereby selecting only data at a depth of 0 m, i.e., at the surface. Note also that we use the [datetime](https://docs.python.org/2/library/datetime.html) package to specify dates and times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_salinity` method produced flattened numpy arrays, the length of which corresponds to the number of data points in the selected geographic region, depth range, and temporal window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47. 47. 47. 47. 47. 47. 47. 47. 47. 47.]\n",
      "[-62.96002197 -62.88000488 -62.79998779 -62.7199707  -62.64001465\n",
      " -62.55999756 -62.47998047 -62.40002441 -62.32000732 -62.23999023]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[113991. 113991. 113991. 113991. 113991. 113991. 113991. 113991. 113991.\n",
      " 113991.]\n",
      "[30.791 30.886 30.92  30.903 30.874 30.853 30.817 30.747 30.714 30.636]\n"
     ]
    }
   ],
   "source": [
    "# print the first 10 values of each array\n",
    "\n",
    "print(lat[0:10])      # latitude (degrees north)\n",
    "print(lon[0:10])      # longitude (degrees west)\n",
    "print(depth[0:10])    # depth (meters)\n",
    "print(epoch[0:10])     # time (hours since 00:00:00 on 1 January 2000)\n",
    "print(salinity[0:10]) # ocean salt content (g/kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `epoch_2_dt` function from Kadlu's `data_util` module to convert the time values into a more human-friendly date-time format, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-01 15:00:00\n"
     ]
    }
   ],
   "source": [
    "print(kadlu.epoch_2_dt(epoch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sources\n",
    "Kadlu includes functionality to load data from a variety of different data sources. For a high level overview, print the source_map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    CHS   (Canadian Hydrography Service)\n",
      "          load_bathymetry:          bathymetric data in Canada's waterways. metres, variable resolution \n",
      "\n",
      "    GEBCO (General Bathymetric Chart of the Oceans)\n",
      "          load_bathymetry:          global bathymetric and topographic data. metres below sea level \n",
      "\n",
      "    ERA5  (Global environmental dataset from Copernicus Climate Data Store)\n",
      "          load_windwaveswellheight: combined height of wind, waves, and swell. metres\n",
      "          load_wavedirection:       mean wave direction, degrees\n",
      "          load_waveperiod:          mean wave period, seconds\n",
      "          load_wind_uv:             wind speed computed as sqrt(u^2 + v^2) / 2, where u, v are direction vectors\n",
      "          load_wind_u:              wind speed coordinate U-vector, m/s\n",
      "          load_wind_v:              wind speed coordinate V-vector, m/s \n",
      "\n",
      "    HYCOM (Hybrid Coordinate Ocean Model)\n",
      "          load_salinity:            g/kg salt in water\n",
      "          load_temp:                degrees celsius\n",
      "          load_water_uv:            ocean current computed as sqrt(u^2 + v^2) / 2, where u, v are direction vectors\n",
      "          load_water_u:             ocean current coordinate U-vector, m/s\n",
      "          load_water_v:             ocean current coordinate V-vector, m/s \n",
      "\n",
      "    WWIII (WaveWatch Ocean Model Gen 3)\n",
      "          load_wavedirection:       primary wave direction, degrees\n",
      "          load_waveperiod:          primary mean wave period, seconds\n",
      "          load_windwaveheight:      combined height of wind and waves, metres\n",
      "          load_wind_uv:             wind speed computed as sqrt(u^2 + v^2) / 2, where u, v are direction vectors\n",
      "          load_wind_u:              wind speed coordinate U-vector, m/s\n",
      "          load_wind_v:              wind speed coordinate V-vector, m/s\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(source_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for more information on a specific source, print the class object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Native hycom .[ab] data converted to NetCDF at the Naval\n",
      "Research Laboratory, interpolated to 0.08° grid between\n",
      "40°S-40°N (0.04° poleward) containing 40 z-levels.\n",
      "Availability: 1994 to 2015\n",
      "\thttps://www.hycom.org/data/glbv0pt08\n",
      "\n",
      "function input arguments:\n",
      "\t(south, north, west, east, start, end, top, bottom)\n",
      "\n",
      "class functions:\n",
      "\tload_salinity\n",
      "\tload_temp\n",
      "\tload_water_u\n",
      "\tload_water_uv\n",
      "\tload_water_v\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hycom())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keyword arguments can be passed as a dictionary when using the same load arguments for multiple datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 02:24:50  loading elevation from The GEBCO_2020 Grid - a continuous terrain model for oceans and land at 15 arc-second intervals\n",
      "2020-06-15 02:28:32  ERA5 2013-01-01 significant_height_of_combined_wind_waves_and_swell: processed and inserted 529 rows in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m. 0 duplicates ignored\n",
      "2020-06-15 02:28:35  ERA5 2013-01-01 significant_height_of_combined_wind_waves_and_swell: processed and inserted 414 rows in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:28:39  ERA5 2013-01-01 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:28:42  ERA5 2013-01-01 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m. 207 duplicates ignored\n",
      "2020-06-15 02:28:53  ERA5 2013-01-02 significant_height_of_combined_wind_waves_and_swell: processed and inserted 529 rows in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m. 0 duplicates ignored\n",
      "2020-06-15 02:28:56  ERA5 2013-01-02 significant_height_of_combined_wind_waves_and_swell: processed and inserted 414 rows in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:28:59  ERA5 2013-01-02 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:29:02  ERA5 2013-01-02 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m. 207 duplicates ignored\n",
      "2020-06-15 02:29:13  ERA5 2013-01-03 significant_height_of_combined_wind_waves_and_swell: processed and inserted 529 rows in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m. 0 duplicates ignored\n",
      "2020-06-15 02:29:16  ERA5 2013-01-03 significant_height_of_combined_wind_waves_and_swell: processed and inserted 414 rows in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:29:19  ERA5 2013-01-03 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:29:22  ERA5 2013-01-03 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m. 207 duplicates ignored\n",
      "2020-06-15 02:29:34  ERA5 2013-01-04 significant_height_of_combined_wind_waves_and_swell: processed and inserted 529 rows in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m. 0 duplicates ignored\n",
      "2020-06-15 02:29:37  ERA5 2013-01-04 significant_height_of_combined_wind_waves_and_swell: processed and inserted 414 rows in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:29:40  ERA5 2013-01-04 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:29:43  ERA5 2013-01-04 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m. 207 duplicates ignored\n",
      "2020-06-15 02:30:06  ERA5 2013-01-05 significant_height_of_combined_wind_waves_and_swell: processed and inserted 529 rows in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m. 0 duplicates ignored\n",
      "2020-06-15 02:30:08  ERA5 2013-01-05 significant_height_of_combined_wind_waves_and_swell: processed and inserted 414 rows in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:30:12  ERA5 2013-01-05 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:30:15  ERA5 2013-01-05 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m. 207 duplicates ignored\n",
      "2020-06-15 02:30:26  ERA5 2013-01-06 significant_height_of_combined_wind_waves_and_swell: processed and inserted 529 rows in region 46.00°N,64.00°W,0m:48.00°N,62.00°W,5000m. 0 duplicates ignored\n",
      "2020-06-15 02:30:29  ERA5 2013-01-06 significant_height_of_combined_wind_waves_and_swell: processed and inserted 414 rows in region 48.00°N,64.00°W,0m:50.00°N,62.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:30:31  ERA5 2013-01-06 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 46.00°N,62.00°W,0m:48.00°N,60.00°W,5000m. 115 duplicates ignored\n",
      "2020-06-15 02:30:34  ERA5 2013-01-06 significant_height_of_combined_wind_waves_and_swell: processed and inserted 368 rows in region 48.00°N,62.00°W,0m:50.00°N,60.00°W,5000m. 207 duplicates ignored\n",
      "2020-06-15 02:32:25  loading elevation from The GEBCO_2020 Grid - a continuous terrain model for oceans and land at 15 arc-second intervals\n",
      "2020-06-15 02:44:06  loading elevation from The GEBCO_2020 Grid - a continuous terrain model for oceans and land at 15 arc-second intervals\n",
      "2020-06-15 02:44:39  loading elevation from The GEBCO_2020 Grid - a continuous terrain model for oceans and land at 15 arc-second intervals\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(\n",
    "        south=47, west=-63, \n",
    "        north=49, east=-61, \n",
    "        bottom=0, top=0,\n",
    "        start=datetime(2013, 1, 1), end=datetime(2013, 1, 7))\n",
    "\n",
    "bathy1, lat1, lon1 = gebco().load_bathymetry(**kwargs)\n",
    "\n",
    "waveheight2, lat2, lon2, epoch2 = era5().load_windwaveswellheight(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual loading from netcdf and geotiff \n",
    "Kadlu can load from arbitrary netcdf- and geotiff-formatted data using the functions 'load_netcdf_2D' and 'load_geotiff_2D'. In the case of netcdf databases, the data must contain three variables, two of which are 'lat' and 'lon'. Kadlu will make an assumption that the X and Y axis are specified in coordinate degrees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kadlu import load_netcdf_2D\n",
    "\n",
    "kwargs = dict(south=47, west=-63, north=49, east=-61)\n",
    "\n",
    "bathy3, lat3, lon3 = load_netcdf_2D(filename='/storage/gebco_bathy.nc', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading from an arbitrary netcdf database, data transformation must be done by the user. For example, when loading GEBCO netcdf data directly from the file instead of the gebco().load_bathymetry function, bathymetric values will be returned as a measure of elevation (equal to depth * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4339, -4339, -4340, ..., -4902, -4902, -4901],\n",
       "       [-4345, -4343, -4343, ..., -4905, -4903, -4903],\n",
       "       [-4345, -4349, -4349, ..., -4905, -4905, -4906],\n",
       "       ...,\n",
       "       [-5253, -5253, -5254, ..., -5252, -5252, -5252],\n",
       "       [-5248, -5250, -5250, ..., -5252, -5252, -5252],\n",
       "       [-5248, -5240, -5246, ..., -5254, -5253, -5253]], dtype=int16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a 2D array of elevation values\n",
    "bathy3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
